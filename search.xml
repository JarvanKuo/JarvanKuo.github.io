<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[hexo笔记]]></title>
    <url>%2F2019%2F09%2F18%2Fhexo%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[hexo的一些配置和命令 hexo 常用指令1234hexo new "post title with whitespace" // 新增md文章hexo clean // 清除hexo g // 生成静态文件。hexo g -d // 文件生成后立即部署网站 站内文章跳转通过内置的标签插件的语法post_link来实现引用 1&#123;% post_link 文章文件名（不要后缀） 文章标题（可选） %&#125; hexo安装请看 官网 NexT主题使用流行的NexT，NexT官网 默认主题插件扩展请看 个人网站的功能插件 评论插件-gitalk记录如何在hexo next主题下配置gitalk评论系统 修改内容区宽度NexT | 修改内容区域的宽度 添加文章阴影Hexo博客NexT主题下添加文章边框阴影效果 文章摘要设置站点首页不显示文章全文 修改配置文件_config.yml 12345# Automatically Excerpt. Not recommend.# Please use &lt;!-- more --&gt; in the post to control excerpt accurately.auto_excerpt: enable: false length: 150 注：使用&lt;!-- more --&gt;标志来精确控制文章的摘要预览，通常在文章开头写一下概要。 一篇文章多个 categoriesHexo 一篇文章多个 categories:这里yaml语法错误，列表-的后面没有空格 YAML配置文件 子分类 12345categories: - Java - Servlet# 或者下面写法categories: [Java, Servlet] 同级多个分类 12345678910categories: [[Java], [Servlet]] # yaml兼容Json的语法，直接写Json串categories: [[Java, Servlet], [Servlet2]] # 包含子分类# 或者下面写法categories: - [Java] - [Servlet]# 下面包含子分类categories: - [Java, Servlet] - [Programming]]]></content>
      <categories>
        <category>建站</category>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux笔记]]></title>
    <url>%2F2019%2F09%2F17%2Flinux%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[linux相关命令、配置。 参考文献： 命令 字符编码转换 iconv命令 iconv命令是用来转换文件的编码方式的 12345678910111213141516# 语法iconv -f encoding [-t encoding] [inputfile]... # 选项-f encoding :把字符从encoding编码开始转换。 -t encoding :把字符转换到encoding编码。 -l :列出已知的编码字符集合 -o file :指定输出文件 -c :忽略输出的非法字符 -s :禁止警告信息，但不是错误信息 --verbose :显示进度信息 -f和-t所能指定的合法字符在-l选项的命令里面都列出来了。 # 列出当前支持的字符编码： iconv -l # 将文件file1转码，转后文件输出到fil2中： iconv file1 -f EUC-JP-MS -t UTF-8 -o file2]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSDB数据库笔记]]></title>
    <url>%2F2019%2F09%2F17%2FSSDB%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[SSDB：一个高性能的支持丰富数据结构的 NoSQL 数据库, 用于替代 Redis. 参考文献： SSDB官网 环境win10 下 wsl 环境 ubuntu 的 ssdb 配置文件配置文件使用Tab而不是空格做缩排（复制到配置文件后请把空格替换为Tab） 1234567891011121314151617181920212223242526272829work_dir = /usr/data/ssdb_8883 pidfile = /usr/data/ssdb_8883.pid server: ip: 0.0.0.0 port: 8883 allow: 127.0.0.1 allow: 192.168 replication: binlog: yes sync_speed: -1 slaveof: type: sync ip: 127.0.0.1 port: 8881 logger: level: error output: /usr/data/ssdb_8883.log rotate: size: 1000000000 leveldb: cache_size: 500 block_size: 32 write_buffer_size: 64 compaction_speed: 1000 compression: yes 启动服务器123nohup /usr/servers/ssdb-1.8.2/ssdb-server /usr/chapter7/ssdb_desc_8883.conf &amp; ps -aux | grep ssdb # 命令看是否启动了tail -f nohup.out # 查看错误信息 客户端ssdb-server 是服务器的程序, ssdb-cli 是命令⾏的客户端 123/usr/servers/ssdb-1.8.2/tools/ssdb-cli -p 8888 # 因为SSDB支持Redis协议，所以用Redis客户端也可以访问/usr/servers/redis-2.8.19/src/redis-cli -p 8888]]></content>
      <categories>
        <category>数据库</category>
        <category>SSDB</category>
      </categories>
      <tags>
        <tag>SSDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring笔记]]></title>
    <url>%2F2019%2F09%2F17%2Fspring%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[spring的一些坑！ 参考文献： spring容器 Spring中自己new出来的对象不能自动注入对象和属性 原因 @Autowired注入时是将类交给Springboot管理，而new出来的实例脱离了Springboot的管理，两个东西不在一个管理者管理下，所以没法联系在一起，@Autowired注入就会为null。 解决方法 不要用new的方式实例化，也采用注解的方式，在需要new的实例类上加@Component注解，通过注入的方式使用实例化类。 使用ApplicationContextAware和反射方式获取容器的bean重新set进去 参考：自己new的对象怎么注入spring管理的对象 ##]]></content>
      <categories>
        <category>java</category>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[atlas笔记]]></title>
    <url>%2F2019%2F09%2F17%2Fatlas%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[atlas：mysql-proxy扩展，mysql中间件，可以实现分表、分库（sharding版本）、读写分离、数据库连接池等功能！ Atlas类似于Twemproxy，是Qihoo 360基于Mysql Proxy开发的一个Mysql中间件，据称每天承载读写请求数达几十亿，可以实现分表、分库（sharding版本）、读写分离、数据库连接池等功能，缺点是没有实现跨库分表功能，需要在客户端使用分库逻辑，目前Atlas不活跃 参考文献： 环境win10 下 wsl 环境 ubuntu 的 atlas Mysql+Atlas配置 ubuntu 下安装 Atlas 源码安装方式：请参考第六章 Web开发实战1——HTTP服务 源码编译方法不行的话，直接下载DEB包后用dpkg -i安装即可，注意：旧版本才有DEB包 12wget https://github.com/Qihoo360/Atlas/releases/download/2.2/Atlas-2.2-debian7.0-x86_64.debdpkg -i Atlas-2.2-debian7.0-x86_64.deb ubuntu 下启动 Atlas 缺失 libmysqlclient.so.18 参考：启动zabbix报缺少libmysqlclient.so.18，请自行下载： 123456# 先查找一下whereis libmysqlclient.so.18# 如果存在则软连接到库路径$ ln -s /usr/local/mysql/lib/libmysqlclient.so.18 /usr/lib64/libmysqlclient.so.18# 没有则下载后链接wget -O /usr/lib/libmysqlclient.so.18 http://files.directadmin.com/services/es_7.0_64/libmysqlclient.so.18 atlas配置 1vim /usr/local/mysql-proxy/conf/chapter6.cnf Atlas启动/重启/停止 12# chapter6 即上述的 chapter6.cnf/usr/local/mysql-proxy/bin/mysql-proxyd chapter6 &#123; start | restart | stop &#125; atlas管理 12mysql -h127.0.0.1 -P1113 -uadmin -p123456 SELECT * FROM help # 查看帮助 atlas 客户端 1234567891011# 通过代理端口进入客户端mysql -h127.0.0.1 -P1112 -uroot -p123456use chapter6; insert into ad values(1 '测试1); insert into ad values(2, '测试2'); insert into ad values(3 '测试3); select * from ad where sku_id=1; select * from ad where sku_id=2; #通过如下sql可以看到实际的分表结果 select * from ad_0; select * from ad_1;]]></content>
      <categories>
        <category>数据库</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>atlas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[API接口安全处理]]></title>
    <url>%2F2019%2F09%2F17%2FAPI%E6%8E%A5%E5%8F%A3%E5%AE%89%E5%85%A8%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[开放API接口安全处理！ 参考文献： 公钥，私钥和数字签名这样最好理解 (转载) 概念存在问题： 数据窃取 数据篡改 数据泄露 对应解决方法： 加密：RSA/DES 混淆算法：MD5 令牌：TOKEN 加密 对称 DES AES 非对称（公私钥） RSA 作用： - 加密：公钥加密-&gt;私钥解密 - 签名：私钥加密-&gt;公钥解密（私钥数字签名，公钥验证身份） MD5 Message Digest Algorithm MD5（中文名为消息摘要算法第五版）为计算机安全领域广泛使用的一种散列函数，用以提供消息的完整性保护。 MD5算法特点： 压缩性：任意长度的数据，算出的MD5值长度都是固定的。 容易计算：从原数据计算出MD5值很容易。 抗修改性：对原数据进行任何改动，哪怕只修改1个字节，所得到的MD5值都有很大区别。 强抗碰撞：已知原数据和其MD5值，想找到一个具有相同MD5值的数据（即伪造数据）是非常困难的。 原理上不能破解，不可逆算法 但是有些数字可以由彩虹表（数据非常庞大）的碰撞来获取 MD5加盐 MD5(“”+””+salt) 应用场景 接口规定根据那些字段生成MD5 接口获取第三方调用者的参数来生成对应的MD5和传入的MD5比较 可以校验表单数据的完整性，防篡改 Token通常在登录时获取，判断用户是否登录状态 开放api参数 id主键不要设置成自增序列 自增序列会容易给轮询，爬虫 重复提交，恶意调用场景：交易类，订单类，有效期，幂等性 返回服务器时间戳参数，调用时传入，与当前服务器时间比较，有效期内才通过 随机数 日志验证码短信类：图形验证码 注册下发短信：没有用户信息，无法从业务上限制，只能弄人机交互的验证码]]></content>
      <categories>
        <category>java</category>
        <category>接口规范</category>
      </categories>
      <tags>
        <tag>加解密</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty安装笔记]]></title>
    <url>%2F2019%2F09%2F17%2Fopenresty%E5%AE%89%E8%A3%85%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[openresty安装在ubuntu下的安装 参考 安装OpenResty(Nginx+Lua)开发环境 安装步骤：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# 创建目录/usr/servers，以后我们把所有软件安装在此目录mkdir -p /usr/servers cd /usr/servers/ # 安装依赖apt-get install libreadline-dev libncurses5-dev libpcre3-dev libssl-dev perl # 下载ngx_openresty-1.7.7.2.tar.gz并解压wget http://openresty.org/download/ngx_openresty-1.7.7.2.tar.gz tar -xzvf ngx_openresty-1.7.7.2.tar.gz # 安装LuaJITcd /usr/servers/ngx_openresty-1.7.7.2/bundle/LuaJIT-2.1-20150120/ # 没有安装make的需要先安装 apt install make apt install make-guile # 没安装gcc的需要先执行以下命令 sudo apt-get build-dep gcc make clean &amp;&amp; make &amp;&amp; make install ln -sf luajit-2.1.0-alpha /usr/local/bin/luajit # 下载ngx_cache_purge模块，该模块用于清理nginx缓存cd /usr/servers/ngx_openresty-1.7.7.2/bundle wget https://github.com/FRiCKLE/ngx_cache_purge/archive/2.3.tar.gz tar -xvf 2.3.tar.gz # 下载nginx_upstream_check_module模块，该模块用于ustream健康检查cd /usr/servers/ngx_openresty-1.7.7.2/bundle wget https://github.com/yaoweibin/nginx_upstream_check_module/archive/v0.3.0.tar.gz tar -xvf v0.3.0.tar.gz # 安装ngx_openrestycd /usr/servers/ngx_openresty-1.7.7.2 ./configure --prefix=/usr/servers --with-http_realip_module --with-pcre --with-luajit --add-module=./bundle/ngx_cache_purge-2.3/ --add-module=./bundle/nginx_upstream_check_module-0.3.0/ -j2 # 报错 checking for zlib library ... not found，需要安装 zlib sudo apt-get install zlib1g-devmake &amp;&amp; make install # 报错 recipe for target 'objs/src/event/ngx_event_openssl.o' failed，openssl版本问题，需要安装旧版本 # 需要指定旧版本，推荐在编译 Nginx 时指定 OpenSSL 源码目录，而不是使用系统自带的版本，这样更可控 cd /usr/servers/ngx_openresty-1.7.7.2/bundle wget -O openssl.tar.gz -c https://github.com/openssl/openssl/archive/OpenSSL_1_0_2k.tar.gz tar zxf openssl.tar.gz mv openssl-OpenSSL_1_0_2k/ openssl # 重新配置 ngx_openresty cd /usr/servers/ngx_openresty-1.7.7.2 ./configure \ --prefix=/usr/servers \ --with-http_realip_module \ --with-pcre \ --with-luajit \ --add-module=./bundle/ngx_cache_purge-2.3/ \ --add-module=./bundle/nginx_upstream_check_module-0.3.0/ \ --with-openssl=./bundle/openssl \ -j2 # 重新make make &amp;&amp; make install # 启动nginx，访问 http://localhost/ 成功即可/usr/servers/nginx/sbin/nginx 拓展： ubuntu gcc 安装 使用 ubantu下安装zlib的方法 Nginx 配置之完整篇]]></content>
      <categories>
        <category>服务器</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ForkJoin框架]]></title>
    <url>%2F2019%2F09%2F17%2FForkJoin%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[ForkJoin框架概要！ 参考文献： Java–8–新特性–串并行流与ForkJoin框架 ForkJoin框架概念Fork/Join框架：在必要的情况下，将一个大任务，进行拆分（fork） 成若干个子任务（拆到不能再拆，这里就是指我们制定的拆分的临界值），再将一个个小任务的结果进行join汇总。 Fork/Join与传统线程池的区别Fork/Join采用“工作窃取模式”，当执行新的任务时他可以将其拆分成更小的任务执行，并将小任务加到线程队列中，然后再从一个随即线程中偷一个并把它加入自己的队列中。]]></content>
      <categories>
        <category>java</category>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>ForkJoin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown笔记]]></title>
    <url>%2F2019%2F09%2F17%2Fmarkdown%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[markdown总结！ 参考文献： Markdown创建表格 markdown创建表格 极简方式 name 价格 数量 香蕉 $1 5 苹果 $1 6 草莓 $1 7 格式化 name 111 222 333 444 aaa bbb ccc ddd eee fff ggg hhh iii 000]]></content>
      <categories>
        <category>编辑器</category>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置]]></title>
    <url>%2F2019%2F09%2F17%2Fnginx%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[nginx的命令，配置！ nginx工作原理Nginx工作原理（Master+Worker） nginx常用命令 测试配置文件 1nginx -t 启动： 指定配置文件 1nginx -p `pwd`/ -c conf/nginx.conf 停止： nginx指定配置文件的，停止时也需指定参数 1nginx -p `pwd`/ -c conf/nginx.conf -s quit nginx概念 upstream 负载均衡概要 upstream 是 Nginx 的 HTTP Upstream 模块，这个模块通过一个简单的调度算法来实现客户端 IP 到后端服务器的负载均衡 123456789101112upstream test.net&#123; ip_hash; server 192.168.10.13:80; server 192.168.10.14:80 down; server 192.168.10.15:8009 max_fails=3 fail_timeout=20s; server 192.168.10.16:8080;&#125;server &#123; location / &#123; proxy_pass http://test.net; &#125;&#125;]]></content>
      <categories>
        <category>服务器</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis笔记]]></title>
    <url>%2F2019%2F09%2F17%2Fredis%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[redis笔记！ 参考文献： 第三章 Redis/SSDB+Twemproxy安装与使用 nohup和&amp;使用 Twemproxy-缓存代理分片机制 环境win10 下 wsl 环境 ubuntu 的 redis Redis安装与使用 下载redis并安装 12345cd /usr/servers/ wget https://github.com/antirez/redis/archive/2.8.19.tar.gz tar -xvf 2.8.19.tar.gz cd redis-2.8.19/ make 后台启动Redis服务器 使用 nohup 和 &amp; 指令： 12nohup /usr/servers/redis-2.8.19/src/redis-server /usr/servers/redis-2.8.19/redis.conf &amp;` 查看是否启动成功 1ps -ef | grep redis 进入客户端并测试 123456/usr/servers/redis-2.8.19/src/redis-cli -p 6379 127.0.0.1:6379&gt; set i 1 OK 127.0.0.1:6379&gt; get i "1" 127.0.0.1:6379&gt; quit # quit 退出 redis 客户端 redis客户端显示中文 1./redis-cli -- raw # 默认redis不转义中文的，需要加上 --raw redis-cli查看所有的keys及清空所有的数据 12keys * # 查看所有keysflushall # 清空所有数据 Redis主从 基本设置 1234567891011121314151617181920212223242526#端口设置，默认6379 port 6379 #日志文件，默认/dev/null logfile &quot;&quot;#内存大小对应关系 # 1k =&gt; 1000 bytes # 1kb =&gt; 1024 bytes # 1m =&gt; 1000000 bytes # 1mb =&gt; 1024*1024 bytes # 1g =&gt; 1000000000 bytes # 1gb =&gt; 1024*1024*1024 bytes #设置Redis占用100mb的大小 maxmemory 100mb #如果内存满了就需要按照如相应算法进行删除过期的/最老的 #volatile-lru 根据LRU算法移除设置了过期的key #allkeys-lru 根据LRU算法移除任何key(包含那些未设置过期时间的key) #volatile-random/allkeys-&gt;random 使用随机算法而不是LRU进行删除 #volatile-ttl 根据Time-To-Live移除即将过期的key #noeviction 永不过期，而是报错 maxmemory-policy volatile-lru #Redis并不是真正的LRU/TTL，而是基于采样进行移除的，即如采样10个数据移除其中最老的/即将过期的 maxmemory-samples 10 Redis主从 12345678910111213141516#在配置文件中挂载主从，不推荐这种方式，我们实际应用时Redis可能是会宕机的 slaveof masterIP masterPort #从是否只读，默认yes slave-read-only yes #当从失去与主的连接或者复制正在进行时，从是响应客户端（可能返回过期的数据）还是返回“SYNC with master in progress”错误，默认yes响应客户端 slave-serve-stale-data yes #从库按照默认10s的周期向主库发送PING测试连通性 repl-ping-slave-period 10 #设置复制超时时间（SYNC期间批量I/O传输、PING的超时时间），确保此值大于repl-ping-slave-period #repl-timeout 60 #当从断开与主的连接时的复制缓存区，仅当第一个从断开时创建一个，缓存区越大从断开的时间可以持续越长 # repl-backlog-size 1mb #当从与主断开持续多久时清空复制缓存区，此时从就需要全量复制了，如果设置为0将永不清空 # repl-backlog-ttl 3600 #slave客户端缓存区，如果缓存区超过256mb将直接断开与从的连接，如果持续60秒超过64mb也会断开与从的连接 client-output-buffer-limit slave 256mb 64mb 60 设置主从 123456789101112131415161718192021cd /usr/servers/redis-2.8.19 cp redis.conf redis_6660.conf cp redis.conf redis_6661.conf # 将端口分别改为port 6660和port 6661vim redis_6660.conf vim redis_6661.conf # 启动nohup /usr/servers/redis-2.8.19/src/redis-server /usr/servers/redis-2.8.19/redis_6660.conf &amp; nohup /usr/servers/redis-2.8.19/src/redis-server /usr/servers/redis-2.8.19/redis_6661.conf &amp; # 查看是否启动成功ps -aux | grep redis # 进入从客户端，挂主（不在配置文件设置 slaveof masterIP masterPort ）/usr/servers/redis-2.8.19/src/redis-cli -p 6661 127.0.0.1:6661&gt; slaveof 127.0.0.1 6660 OK 127.0.0.1:6661&gt; info replication # Replication role:slave ... Redis持久化 为了防止数据丢失，可以挂载一个从（叶子节点）只进行持久化存储工作。 Redis持久化有RDB快照模式和AOF追加模式。 Redis动态调整配置 123456789127.0.0.1:6660&gt; config get maxmemory 1) "maxmemory" 2) "10485760"# 调整配置值127.0.0.1:6660&gt; config set maxmemory 20971520 # 上述命令重启redis后该配置会丢失，可以执行如下命令重写配置文件127.0.0.1:6660&gt; config rewrite Redis集群一旦涉及到一台物理机无法存储的情况就需要考虑使用分片机制将数据存储到多台服务器，可以说是Redis集群。 利用 Twemproxy 实现分片、减少连接数、Hash Tag 分片逻辑。 Twemproxy 代理 Twemproxy 配置 12# 配置文件vim /usr/servers/twemproxy-0.4.0/conf/nutcracker.yml 1234567891011server1: listen: 127.0.0.1:1111 ## 监听地址和端口 hash: fnv1a_64 ## 散列算法 distribution: ketama ## 分片的算法，有ketama（一致性hash）、module（取模）、random（随机）三种算法# auto_eject_hosts: true ## 是否在节点无法响应时自动从服务器列表中剔除，重新响应时自动加入服务器列表中# timeout: 1000 hash_tag: "::" redis: true ## 后端代理的是否为redis servers: - 127.0.0.1:6660:1 server1 - 127.0.0.1:6661:1 server2 Twemproxy 启动 1234/usr/servers/twemproxy-0.4.0/src/nutcracker -d -c /usr/servers/twemproxy-0.4.0/conf/nutcracker.ymlps -aux | grep nutcracker# 启动 Redis 客户端对应端口，查看是否代理成功/usr/servers/redis-2.8.19/src/redis-cli -p 1111 或者配置启动/重启/停止脚本方便操作 12chmod +x /usr/servers/twemproxy-0.4.0/scripts/nutcracker.init vim /usr/servers/twemproxy-0.4.0/scripts/nutcracker.init 将OPTIONS改为 OPTIONS=”-d -c /usr/local/twemproxy/conf/nutcracker.yml” 注释掉. /etc/rc.d/init.d/functions； 将daemon –user ${USER} ${prog} $OPTIONS改为${prog} $OPTIONS； [报错]：若nutcracker没设置为全局变量，则会报此错 nutcracker: command not found 写了全路径：/usr/servers/twemproxy-0.4.0/src/${prog} $OPTIONS 将killproc改为killall。 这样就可以使用如下脚本进行启动、重启、停止了。 1nutcracker.init &#123;start|stop|status|restart|reload|condrestart&#125;]]></content>
      <categories>
        <category>数据库</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty配置]]></title>
    <url>%2F2019%2F09%2F17%2Fopenresty%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[openresty配置的一些问题总结！ 环境 win10下的linux子系统ubuntu（wsl） openresty版本：ngx_openresty-1.7.7.2.tar.gz wsl安装请移步 wsl笔记 openresty安装请参考安装OpenResty(Nginx+Lua)开发环境 或者参考 openresty安装笔记 openssl版本问题需要指定旧版本，推荐在编译 Nginx 时指定 OpenSSL 源码目录，而不是使用系统自带的版本，这样更可控。 参考openssl版本问题 Lua模块安装 安装 LuaRocks LuaRocks: Lua 的模块安装和部署工具 1apt-get install luarocks 安装 luasocket lua 远程调试引入的 require(&quot;mobdebug&quot;).start() 需要 socket 注：Lua 的 Remote Debug 远程调试 现在还搞不定，此处占个坑。 1luarocks install luasocket openresty使用nginx常用命令 启动： 指定配置文件 1nginx -p `pwd`/ -c conf/nginx.conf 停止： nginx指定配置文件的，停止时也需指定参数 1nginx -p `pwd`/ -c conf/nginx.conf -s quit nginx.conf 配置 正则匹配路径 模式 含义 location = /uri = 表示精确匹配，只有完全匹配上才能生效 location ^~ /uri ^~ 开头对URL路径进行前缀匹配，并且在正则之前。 location ~ pattern 开头表示区分大小写的正则匹配 location ~* pattern 开头表示不区分大小写的正则匹配 location /uri 不带任何修饰符，也表示前缀匹配，但是在正则匹配之后 location / 通用匹配，任何未匹配到其它location的请求都会匹配到，相当于switch中的default 1234567location ~ ^/api/([-_a-zA-Z0-9]+) &#123; # 准入阶段完成参数验证 access_by_lua_file nginx_test_server/access_check.lua; #内容生成阶段 content_by_lua_file nginx_test_server/$1.lua;&#125; 开发调试时取消缓存 123# 这里设置为 off，是为了避免每次修改之后都要重新 reload 的麻烦。# 在生产环境上务必确保 lua_code_cache 设置成 on。lua_code_cache off; http 模块 报错 bad argument #2 to ‘set_keepalive’ (number expected, got nil) 参考：bad argument #2 to ‘set_keepalive’ (number expected, got nil)的解决办法 在关联数组中多传一个参数keepalive=false 即 12345&#123;method = “GET”,path = requestBody,keepalive=false&#125; lua 的一些坑 openresty/lua-resty-redis 的 批量查询 返回值问题 参考：nil、null与ngx.null 官方说明 A non-nil Redis “bulk reply” results in a Lua string as the return value. A nil bulk reply results in a ngx.null return value. A nil multi-bulk reply returns in a ngx.null value. 如果使用批量查询如mget，查不到数据会返回 ngx.null OpenResty缓存需要先在 nginx.conf 里面的修改 ，这个 cache 是 Nginx 所有 worker 之间共享的 1lua_shared_dict my_cache 128m;]]></content>
      <categories>
        <category>服务器</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[template]]></title>
    <url>%2F2019%2F09%2F17%2Ftemplate%2F</url>
    <content type="text"><![CDATA[这是文章模板！ 参考文献： ## ##]]></content>
      <categories>
        <category>template</category>
        <category>template</category>
      </categories>
      <tags>
        <tag>template</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[wsl笔记]]></title>
    <url>%2F2019%2F09%2F17%2Fwsl%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[wsl 下的 ubuntu 系统一些问题总结！ 参考文献： Windows 10生产力提升之WSL实践 在wsl下安装使用sshd全攻略.md 环境win10 下 wsl 环境安装 ubuntu 修改更新源 备份文件 1sudo cp /etc/apt/sources.list /etc/apt/sources.list.old 使用阿里源 打开文件： 12 sudo vi /etc/apt/sources.list` 整个文件替换成阿里源： 12345678910deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse 更新 12sudo apt-get updatesudo apt-get upgrade 设置超级用户ubuntu的su初始密码设置 1sudo passwd zsh美化终端安装使用oh-my-zsh（Win10+WSL或Ubuntu） 设zsh为默认shell1chsh -s /bin/zsh # 设置 bash 同理 环境变量PATH使用zsh后，环境变量需要在 ~/.zshrc 配置文件中定义，/etc/profile 是不会生效的 开启 ssh 远程连接wsl下的ubuntu自带ssh服务有问题需要卸载重装一遍ssh服务 123456789101112# 重装 openssh-serversudo apt-get remove openssh-serversudo apt-get install openssh-server# 修改 shd_config文件sudo vi /etc/ssh/sshd_config# Port 22 #默认即可，如果有端口占用可以自己修改# PasswordAuthentication yes # 允许用户名密码方式登录# PermitRootLogin yes # 允许管理员ssh登录# 重启ssh服务sudo service ssh restart apt命令与问题[Ubuntu的apt命令详解] 搜索软件 1sudo apt-cache search package_name WSL Ubuntu 解决出现 E: Could not read response to hello message from hook …问题 执行以下命令 1sudo rm -rf /etc/apt/apt.conf.d/20snapd.conf windows 和 wsl 互相访问文件 打开wsl文件 使用explorer.exe，wsl下切换用户就不能使用这个命令。。。 1explorer.exe . 访问windows文件，使用挂载方式/mnt/ 1cd /mnt/c/Users/Ben/Documents/ wsl开机没有自启动ssh需要在wsl中手动运行一下： 1sudo service ssh start 由于是wsl内部是类似docker运行的，没有 systemd 服务 重装python 检查python路径： 123456789# 方式一：type -a python# 方式二：ls -l /usr/bin/pythonls -l /usr/bin/python*# 方式三：which python 安装python2、python3 1234# 安装python2$ sudo apt-get install python# 安装python3$ sudo apt-get install python3]]></content>
      <categories>
        <category>linux</category>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ant笔记]]></title>
    <url>%2F2018%2F09%2F17%2Fant%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[ant的使用，命令！ 参考文献： ant+maven一键打包springboot上传服务器发布 判断linux文件、文件夹是否存在 shell中脚本参数传递的两种方式 shell脚本“syntax error:unexpected end of file”解决方案 ant远程部署 Ant 引用配置文件 123456789&lt;!-- set global properties for this build --&gt; &lt;property file="build.properties"/&gt; &lt;!--输出配置信息--&gt; &lt;target name="show_property" description="show build.properties conf"&gt; &lt;echo&gt; ================== build.properties ================ &lt;/echo&gt; &lt;echo&gt;PROJECT_NAME=$&#123;ant.project.name&#125;&lt;/echo&gt; &lt;echo&gt;DEST_DIR=$&#123;DEST_DIR&#125;&lt;/echo&gt;&lt;/target&gt; target条件控制 12345678910&lt;target name="detect.file" &gt; &lt;condition property="fileIsExists" &gt; &lt;and&gt; &lt;available file="c:/123.txt"/&gt; &lt;/and&gt; &lt;/condition&gt;&lt;/target&gt;&lt;target name="echoDemo" if="fileIsExists" depends="detect.file"&gt; &lt;echo message="hello ant"/&gt;&lt;/target&gt; Ant-sshexec-执行远程服务器或本地脚本 需要先下载第三方依赖包jsch-0.1.46.jar到ant/lib目录 12345678&lt;sshexec host="$&#123;host&#125;"username="$&#123;usr&#125;" password="$&#123;pwd&#125;"trust="true" command="pwd;./test.sh" outputproperty="output" # sh 的输出，可用 $&#123;output&#125; 获取/&gt; scp命令上传文件 1234567&lt;scp todir="$&#123;USERNAME&#125;:$&#123;PASSWORD&#125;@$&#123;SERVER&#125;:$&#123;DEST_DIR&#125;" trust="true"&gt; &lt;fileset dir="$&#123;LOCAL_PATH&#125;"&gt; &lt;exclude name="build.properties"/&gt; &lt;exclude name="build.xml"/&gt; &lt;exclude name=".idea/"/&gt; &lt;/fileset&gt;&lt;/scp&gt; 判断远程文件是否存在 123456#判断文件是否存在if [ -f "/data/filename" ];then echo "文件存在" else echo "文件不存在"fi shell脚本传参 123456789101112#!/bin/bashecho "脚本$0"echo "第一个参数$1"echo "第二个参数$2"# 命令行输入$ ./test.sh 1 2#shell中将会输出：脚本./test.sh # $0获取到的是脚本路径以及脚本名# 后面按顺序获取参数，当参数超过10个时(包括10个)，需要使用$&#123;10&#125;,$&#123;11&#125;....才能获取到参数第一个参数1第二个参数2 shell脚本添加执行权限 chmod是权限管理命令change the permissions mode of a file的缩写。。 u代表所有者，x代表执行权限。 + 表示增加权限。 12chmod u+x file.sh # 就表示对当前目录下的file.sh文件的所有者增加可执行权限。 shell脚本“syntax error:unexpected end of file”解决方案 原因：该脚本在windows下编辑或者在windows打开保存过。 DOS下文件和Linux下文件格式差异问题导致的。 在 idea 中右下角可以选择 LF 为换行标识。 在 服务器可以使用vi修改文件格式，如下： 123vi dos.txt:set fileformat=unix:wq]]></content>
      <categories>
        <category>java</category>
        <category>构建工具</category>
      </categories>
      <tags>
        <tag>ant</tag>
      </tags>
  </entry>
</search>
