<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[hexo笔记]]></title>
    <url>%2F2019%2F09%2F18%2Fhexo%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[hexo的一些配置和命令 hexo 常用指令1234hexo new "post title with whitespace" // 新增md文章hexo clean // 清除hexo g // 生成静态文件。hexo g -d // 文件生成后立即部署网站 站内文章跳转通过内置的标签插件的语法post_link来实现引用 1&#123;% post_link 文章文件名（不要后缀） 文章标题（可选） %&#125; hexo安装请看 官网 NexT主题使用流行的NexT，NexT官网 默认主题插件扩展请看 个人网站的功能插件 评论插件-gitalk记录如何在hexo next主题下配置gitalk评论系统 修改内容区宽度NexT | 修改内容区域的宽度 添加文章阴影Hexo博客NexT主题下添加文章边框阴影效果 文章摘要设置站点首页不显示文章全文 修改配置文件_config.yml 12345# Automatically Excerpt. Not recommend.# Please use &lt;!-- more --&gt; in the post to control excerpt accurately.auto_excerpt: enable: false length: 150 注：使用&lt;!-- more --&gt;标志来精确控制文章的摘要预览，通常在文章开头写一下概要。 一篇文章多个 categoriesHexo 一篇文章多个 categories:这里yaml语法错误，列表-的后面没有空格 YAML配置文件 子分类 12345categories: - Java - Servlet# 或者下面写法categories: [Java, Servlet] 同级多个分类 12345678910categories: [[Java], [Servlet]] # yaml兼容Json的语法，直接写Json串categories: [[Java, Servlet], [Servlet2]] # 包含子分类# 或者下面写法categories: - [Java] - [Servlet]# 下面包含子分类categories: - [Java, Servlet] - [Programming]]]></content>
      <categories>
        <category>建站</category>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty配置]]></title>
    <url>%2F2019%2F09%2F17%2Fopenresty%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[openresty配置的一些问题总结！ 环境 win10下的linux子系统ubuntu（wsl） openresty版本：ngx_openresty-1.7.7.2.tar.gz wsl安装请移步 wsl笔记 openresty安装请参考安装OpenResty(Nginx+Lua)开发环境 或者参考 openresty安装笔记 openssl版本问题需要指定旧版本，推荐在编译 Nginx 时指定 OpenSSL 源码目录，而不是使用系统自带的版本，这样更可控。 参考openssl版本问题 Lua模块安装 安装 LuaRocks LuaRocks: Lua 的模块安装和部署工具 1apt-get install luarocks 安装 luasocket lua 远程调试引入的 require(&quot;mobdebug&quot;).start() 需要 socket 注：Lua 的 Remote Debug 远程调试 现在还搞不定，此处占个坑。 1luarocks install luasocket openresty使用nginx常用命令 启动： 指定配置文件 1nginx -p `pwd`/ -c conf/nginx.conf 停止： nginx指定配置文件的，停止时也需指定参数 1nginx -p `pwd`/ -c conf/nginx.conf -s quit nginx.conf 配置 正则匹配路径 模式 含义 location = /uri = 表示精确匹配，只有完全匹配上才能生效 location ^~ /uri ^~ 开头对URL路径进行前缀匹配，并且在正则之前。 location ~ pattern 开头表示区分大小写的正则匹配 location ~* pattern 开头表示不区分大小写的正则匹配 location /uri 不带任何修饰符，也表示前缀匹配，但是在正则匹配之后 location / 通用匹配，任何未匹配到其它location的请求都会匹配到，相当于switch中的default 1234567location ~ ^/api/([-_a-zA-Z0-9]+) &#123; # 准入阶段完成参数验证 access_by_lua_file nginx_test_server/access_check.lua; #内容生成阶段 content_by_lua_file nginx_test_server/$1.lua;&#125; 开发调试时取消缓存 123# 这里设置为 off，是为了避免每次修改之后都要重新 reload 的麻烦。# 在生产环境上务必确保 lua_code_cache 设置成 on。lua_code_cache off; http 模块 报错 bad argument #2 to ‘set_keepalive’ (number expected, got nil) 参考：bad argument #2 to ‘set_keepalive’ (number expected, got nil)的解决办法 在关联数组中多传一个参数keepalive=false 即 12345&#123;method = “GET”,path = requestBody,keepalive=false&#125; lua 的一些坑 openresty/lua-resty-redis 的 批量查询 返回值问题 参考：nil、null与ngx.null 官方说明 A non-nil Redis “bulk reply” results in a Lua string as the return value. A nil bulk reply results in a ngx.null return value. A nil multi-bulk reply returns in a ngx.null value. 如果使用批量查询如mget，查不到数据会返回 ngx.null OpenResty缓存需要先在 nginx.conf 里面的修改 ，这个 cache 是 Nginx 所有 worker 之间共享的 1lua_shared_dict my_cache 128m;]]></content>
      <categories>
        <category>服务器</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSDB数据库笔记]]></title>
    <url>%2F2019%2F09%2F17%2FSSDB%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[SSDB：一个高性能的支持丰富数据结构的 NoSQL 数据库, 用于替代 Redis. 参考文献： SSDB官网 环境win10 下 wsl 环境 ubuntu 的 ssdb 配置文件配置文件使用Tab而不是空格做缩排（复制到配置文件后请把空格替换为Tab） 1234567891011121314151617181920212223242526272829work_dir = /usr/data/ssdb_8883 pidfile = /usr/data/ssdb_8883.pid server: ip: 0.0.0.0 port: 8883 allow: 127.0.0.1 allow: 192.168 replication: binlog: yes sync_speed: -1 slaveof: type: sync ip: 127.0.0.1 port: 8881 logger: level: error output: /usr/data/ssdb_8883.log rotate: size: 1000000000 leveldb: cache_size: 500 block_size: 32 write_buffer_size: 64 compaction_speed: 1000 compression: yes 启动服务器123nohup /usr/servers/ssdb-1.8.2/ssdb-server /usr/chapter7/ssdb_desc_8883.conf &amp; ps -aux | grep ssdb # 命令看是否启动了tail -f nohup.out # 查看错误信息 客户端ssdb-server 是服务器的程序, ssdb-cli 是命令⾏的客户端 123/usr/servers/ssdb-1.8.2/tools/ssdb-cli -p 8888 # 因为SSDB支持Redis协议，所以用Redis客户端也可以访问/usr/servers/redis-2.8.19/src/redis-cli -p 8888]]></content>
      <categories>
        <category>数据库</category>
        <category>SSDB</category>
      </categories>
      <tags>
        <tag>SSDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hosts文件]]></title>
    <url>%2F2019%2F09%2F17%2Fhosts%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[hosts文件的注意项！ 参考文献： hosts文件位置 windows下 C:\Windows\System32\drivers\etc\hosts linux下 /etc/hosts hosts文件管理工具—SwitchHosts使用SwitchHosts配置的host不生效的原因： windows 的 hosts 文件是gbk编码的，SwitchHosts修改的是UTF-8编码的 1127.0.0.1 picture.com #文件服务器 上面的配置会由于换行符的问题编码问题导致不生效！ 如果要后面注释，请使用英文！（推荐） 文件开头有说明： 123456789# Additionally, comments (such as these) may be inserted on individual# lines or following the machine name denoted by a &apos;#&apos; symbol.## For example:## 102.54.94.97 rhino.acme.com # source server# 38.25.63.10 x.acme.com # x client host127.0.0.1 picture.com # file server 非要写中文请独立一行写注释（推荐） 12# 文件服务器127.0.0.1 picture.com]]></content>
      <categories>
        <category>hosts</category>
      </categories>
      <tags>
        <tag>hosts</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[atlas笔记]]></title>
    <url>%2F2019%2F09%2F17%2Fatlas%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[atlas：mysql-proxy扩展，mysql中间件，可以实现分表、分库（sharding版本）、读写分离、数据库连接池等功能！ Atlas类似于Twemproxy，是Qihoo 360基于Mysql Proxy开发的一个Mysql中间件，据称每天承载读写请求数达几十亿，可以实现分表、分库（sharding版本）、读写分离、数据库连接池等功能，缺点是没有实现跨库分表功能，需要在客户端使用分库逻辑，目前Atlas不活跃 参考文献： 环境win10 下 wsl 环境 ubuntu 的 atlas Mysql+Atlas配置 ubuntu 下安装 Atlas 源码安装方式：请参考第六章 Web开发实战1——HTTP服务 源码编译方法不行的话，直接下载DEB包后用dpkg -i安装即可，注意：旧版本才有DEB包 12wget https://github.com/Qihoo360/Atlas/releases/download/2.2/Atlas-2.2-debian7.0-x86_64.debdpkg -i Atlas-2.2-debian7.0-x86_64.deb ubuntu 下启动 Atlas 缺失 libmysqlclient.so.18 参考：启动zabbix报缺少libmysqlclient.so.18，请自行下载： 123456# 先查找一下whereis libmysqlclient.so.18# 如果存在则软连接到库路径$ ln -s /usr/local/mysql/lib/libmysqlclient.so.18 /usr/lib64/libmysqlclient.so.18# 没有则下载后链接wget -O /usr/lib/libmysqlclient.so.18 http://files.directadmin.com/services/es_7.0_64/libmysqlclient.so.18 atlas配置 1vim /usr/local/mysql-proxy/conf/chapter6.cnf Atlas启动/重启/停止 12# chapter6 即上述的 chapter6.cnf/usr/local/mysql-proxy/bin/mysql-proxyd chapter6 &#123; start | restart | stop &#125; atlas管理 12mysql -h127.0.0.1 -P1113 -uadmin -p123456 SELECT * FROM help # 查看帮助 atlas 客户端 1234567891011# 通过代理端口进入客户端mysql -h127.0.0.1 -P1112 -uroot -p123456use chapter6; insert into ad values(1 '测试1); insert into ad values(2, '测试2'); insert into ad values(3 '测试3); select * from ad where sku_id=1; select * from ad where sku_id=2; #通过如下sql可以看到实际的分表结果 select * from ad_0; select * from ad_1;]]></content>
      <categories>
        <category>数据库</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>atlas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[API接口安全处理]]></title>
    <url>%2F2019%2F09%2F17%2FAPI%E6%8E%A5%E5%8F%A3%E5%AE%89%E5%85%A8%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[开放API接口安全处理！ 参考文献： 公钥，私钥和数字签名这样最好理解 (转载) 概念存在问题： 数据窃取 数据篡改 数据泄露 对应解决方法： 加密：RSA/DES 混淆算法：MD5 令牌：TOKEN 加密 对称 DES AES 非对称（公私钥） RSA 作用： - 加密：公钥加密-&gt;私钥解密 - 签名：私钥加密-&gt;公钥解密（私钥数字签名，公钥验证身份） MD5 Message Digest Algorithm MD5（中文名为消息摘要算法第五版）为计算机安全领域广泛使用的一种散列函数，用以提供消息的完整性保护。 MD5算法特点： 压缩性：任意长度的数据，算出的MD5值长度都是固定的。 容易计算：从原数据计算出MD5值很容易。 抗修改性：对原数据进行任何改动，哪怕只修改1个字节，所得到的MD5值都有很大区别。 强抗碰撞：已知原数据和其MD5值，想找到一个具有相同MD5值的数据（即伪造数据）是非常困难的。 原理上不能破解，不可逆算法 但是有些数字可以由彩虹表（数据非常庞大）的碰撞来获取 MD5加盐 MD5(“”+””+salt) 应用场景 接口规定根据那些字段生成MD5 接口获取第三方调用者的参数来生成对应的MD5和传入的MD5比较 可以校验表单数据的完整性，防篡改 Token通常在登录时获取，判断用户是否登录状态 开放api参数 id主键不要设置成自增序列 自增序列会容易给轮询，爬虫 重复提交，恶意调用场景：交易类，订单类，有效期，幂等性 返回服务器时间戳参数，调用时传入，与当前服务器时间比较，有效期内才通过 随机数 日志验证码短信类：图形验证码 注册下发短信：没有用户信息，无法从业务上限制，只能弄人机交互的验证码]]></content>
      <categories>
        <category>java</category>
        <category>接口规范</category>
      </categories>
      <tags>
        <tag>加解密</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty安装笔记]]></title>
    <url>%2F2019%2F09%2F17%2Fopenresty%E5%AE%89%E8%A3%85%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[openresty安装在ubuntu下的安装 参考 安装OpenResty(Nginx+Lua)开发环境 安装步骤：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# 创建目录/usr/servers，以后我们把所有软件安装在此目录mkdir -p /usr/servers cd /usr/servers/ # 安装依赖apt-get install libreadline-dev libncurses5-dev libpcre3-dev libssl-dev perl # 下载ngx_openresty-1.7.7.2.tar.gz并解压wget http://openresty.org/download/ngx_openresty-1.7.7.2.tar.gz tar -xzvf ngx_openresty-1.7.7.2.tar.gz # 安装LuaJITcd /usr/servers/ngx_openresty-1.7.7.2/bundle/LuaJIT-2.1-20150120/ # 没有安装make的需要先安装 apt install make apt install make-guile # 没安装gcc的需要先执行以下命令 sudo apt-get build-dep gcc make clean &amp;&amp; make &amp;&amp; make install ln -sf luajit-2.1.0-alpha /usr/local/bin/luajit # 下载ngx_cache_purge模块，该模块用于清理nginx缓存cd /usr/servers/ngx_openresty-1.7.7.2/bundle wget https://github.com/FRiCKLE/ngx_cache_purge/archive/2.3.tar.gz tar -xvf 2.3.tar.gz # 下载nginx_upstream_check_module模块，该模块用于ustream健康检查cd /usr/servers/ngx_openresty-1.7.7.2/bundle wget https://github.com/yaoweibin/nginx_upstream_check_module/archive/v0.3.0.tar.gz tar -xvf v0.3.0.tar.gz # 安装ngx_openrestycd /usr/servers/ngx_openresty-1.7.7.2 ./configure --prefix=/usr/servers --with-http_realip_module --with-pcre --with-luajit --add-module=./bundle/ngx_cache_purge-2.3/ --add-module=./bundle/nginx_upstream_check_module-0.3.0/ -j2 # 报错 checking for zlib library ... not found，需要安装 zlib sudo apt-get install zlib1g-devmake &amp;&amp; make install # 报错 recipe for target 'objs/src/event/ngx_event_openssl.o' failed，openssl版本问题，需要安装旧版本 # 需要指定旧版本，推荐在编译 Nginx 时指定 OpenSSL 源码目录，而不是使用系统自带的版本，这样更可控 cd /usr/servers/ngx_openresty-1.7.7.2/bundle wget -O openssl.tar.gz -c https://github.com/openssl/openssl/archive/OpenSSL_1_0_2k.tar.gz tar zxf openssl.tar.gz mv openssl-OpenSSL_1_0_2k/ openssl # 重新配置 ngx_openresty cd /usr/servers/ngx_openresty-1.7.7.2 ./configure \ --prefix=/usr/servers \ --with-http_realip_module \ --with-pcre \ --with-luajit \ --add-module=./bundle/ngx_cache_purge-2.3/ \ --add-module=./bundle/nginx_upstream_check_module-0.3.0/ \ --with-openssl=./bundle/openssl \ -j2 # 重新make make &amp;&amp; make install # 启动nginx，访问 http://localhost/ 成功即可/usr/servers/nginx/sbin/nginx 拓展： ubuntu gcc 安装 使用 ubantu下安装zlib的方法 Nginx 配置之完整篇]]></content>
      <categories>
        <category>服务器</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux笔记]]></title>
    <url>%2F2019%2F09%2F17%2Flinux%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[linux相关命令、配置。 参考文献： 命令 字符编码转换 iconv命令 iconv命令是用来转换文件的编码方式的 12345678910111213141516# 语法iconv -f encoding [-t encoding] [inputfile]... # 选项-f encoding :把字符从encoding编码开始转换。 -t encoding :把字符转换到encoding编码。 -l :列出已知的编码字符集合 -o file :指定输出文件 -c :忽略输出的非法字符 -s :禁止警告信息，但不是错误信息 --verbose :显示进度信息 -f和-t所能指定的合法字符在-l选项的命令里面都列出来了。 # 列出当前支持的字符编码： iconv -l # 将文件file1转码，转后文件输出到fil2中： iconv file1 -f EUC-JP-MS -t UTF-8 -o file2 rm与管道使用 linux shell: rm 、ls、grep 关于 find grep xargs 命令总结 find、xargs、grep基本用法 ls 与 grep 结合 12ls -l | grep ^d # 列出当前路径下的所有文件夹rm -fr `ls | grep -v "^space.txt$"` # greo正则，ls、rm结合 find、xargs、grep配合使用 find命令把匹配到的文件传递给xargs命令，而xargs命令每次只获取一部分文件而不是全部 1find . -name “*.py”|xargs grep test # 从当前目录及其子目录的py文件中搜索test关键字 rm与find联合 1find . -name "*.mp" | xargs rm -rf]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown笔记]]></title>
    <url>%2F2019%2F09%2F17%2Fmarkdown%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[markdown总结！ 参考文献： Markdown创建表格 markdown创建表格 极简方式 12345name | 价格 | 数量 -|-|-香蕉 | $1 | 5 |苹果 | $1 | 6 |草莓 | $1 | 7 | name 价格 数量 香蕉 $1 5 苹果 $1 6 草莓 $1 7 格式化 1234name | 111 | 222 | 333 | 444:-: | :-: | :-: | :-: | :-:aaa | bbb | ccc | ddd | eee| fff | ggg| hhh | iii | 000| name 111 222 333 444 aaa bbb ccc ddd eee fff ggg hhh iii 000 合并表格 单纯的markdown语法是不能实现，由于markdown支持html，我们可以通过表格在html中的table进行实现。 需要注意的一点是，在markdown中使用html代码来实现表格的效果，需要在表格的外面套上 1&lt;escape&gt;&lt;/escape&gt; （转义），防止markdown直接将代码中的行进行转义成回车，不然会出现表格前空了一大块空白。 但同时，引入html会使得markdown的易读易写的特性降低。除非必要，还是推荐使用markdown本身的表格语法。 1234567891011121314151617181920&lt;table&gt; &lt;tr&gt; &lt;th&gt;项目1&lt;/th&gt; &lt;th&gt;项目2&lt;/th&gt; &lt;th&gt;项目3&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;a1&lt;/td&gt; &lt;td colspan="2"&gt;a2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td rowspan="2"&gt;b1&lt;/td&gt; &lt;td&gt;b2&lt;/td&gt; &lt;td&gt;b3&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;c2&lt;/td&gt; &lt;td&gt;c3&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; 项目1 项目2 项目3 a1 a2 b1 b2 b3 c2 c3]]></content>
      <categories>
        <category>编辑器</category>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置]]></title>
    <url>%2F2019%2F09%2F17%2Fnginx%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[nginx的命令，配置！ nginx工作原理Nginx工作原理（Master+Worker） nginx常用命令 测试配置文件 1nginx -t 启动： 指定配置文件 1nginx -p `pwd`/ -c conf/nginx.conf 停止： nginx指定配置文件的，停止时也需指定参数 1nginx -p `pwd`/ -c conf/nginx.conf -s quit nginx添加新模块nginx添加新模块 配置nginx与FastDFS关联配置文件复制 fastdfs-nginx-module 源码中的配置文件到/etc/fdfs 目录， 并修改 123cp /usr/local/leyou/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs/vi /etc/fdfs/mod_fastdfs.conf 修改以下配置： 这里不要在配置项后面写中文注释，不然配置文件不生效！！！ 1234567connect_timeout=10 # 客户端访问文件连接超时时长（单位：秒）tracker_server=192.168.56.101:22122 # tracker服务IP和端口url_have_group_name=true # 访问链接前缀加上组名store_path0=/leyou/storage # 文件存储路径 复制 FastDFS 的部分配置文件到/etc/fdfs 目录 12cd /usr/local/leyou/FastDFS/conf/cp http.conf mime.types /etc/fdfs/ nginx概念 upstream 负载均衡概要 upstream 是 Nginx 的 HTTP Upstream 模块，这个模块通过一个简单的调度算法来实现客户端 IP 到后端服务器的负载均衡 123456789101112upstream test.net&#123; ip_hash; server 192.168.10.13:80; server 192.168.10.14:80 down; server 192.168.10.15:8009 max_fails=3 fail_timeout=20s; server 192.168.10.16:8080;&#125;server &#123; location / &#123; proxy_pass http://test.net; &#125;&#125;]]></content>
      <categories>
        <category>服务器</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis笔记]]></title>
    <url>%2F2019%2F09%2F17%2Fredis%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[redis笔记！ 参考文献： 第三章 Redis/SSDB+Twemproxy安装与使用 nohup和&amp;使用 Twemproxy-缓存代理分片机制 环境win10 下 wsl 环境 ubuntu 的 redis Redis安装与使用 下载redis并安装 12345cd /usr/servers/ wget https://github.com/antirez/redis/archive/2.8.19.tar.gz tar -xvf 2.8.19.tar.gz cd redis-2.8.19/ make 后台启动Redis服务器 使用 nohup 和 &amp; 指令： 12nohup /usr/servers/redis-2.8.19/src/redis-server /usr/servers/redis-2.8.19/redis.conf &amp;` 查看是否启动成功 1ps -ef | grep redis 进入客户端并测试 123456/usr/servers/redis-2.8.19/src/redis-cli -p 6379 127.0.0.1:6379&gt; set i 1 OK 127.0.0.1:6379&gt; get i "1" 127.0.0.1:6379&gt; quit # quit 退出 redis 客户端 redis客户端显示中文 1./redis-cli -- raw # 默认redis不转义中文的，需要加上 --raw redis-cli查看所有的keys及清空所有的数据 12keys * # 查看所有keysflushall # 清空所有数据 Redis主从 基本设置 1234567891011121314151617181920212223242526#端口设置，默认6379 port 6379 #日志文件，默认/dev/null logfile &quot;&quot;#内存大小对应关系 # 1k =&gt; 1000 bytes # 1kb =&gt; 1024 bytes # 1m =&gt; 1000000 bytes # 1mb =&gt; 1024*1024 bytes # 1g =&gt; 1000000000 bytes # 1gb =&gt; 1024*1024*1024 bytes #设置Redis占用100mb的大小 maxmemory 100mb #如果内存满了就需要按照如相应算法进行删除过期的/最老的 #volatile-lru 根据LRU算法移除设置了过期的key #allkeys-lru 根据LRU算法移除任何key(包含那些未设置过期时间的key) #volatile-random/allkeys-&gt;random 使用随机算法而不是LRU进行删除 #volatile-ttl 根据Time-To-Live移除即将过期的key #noeviction 永不过期，而是报错 maxmemory-policy volatile-lru #Redis并不是真正的LRU/TTL，而是基于采样进行移除的，即如采样10个数据移除其中最老的/即将过期的 maxmemory-samples 10 Redis主从 12345678910111213141516#在配置文件中挂载主从，不推荐这种方式，我们实际应用时Redis可能是会宕机的 slaveof masterIP masterPort #从是否只读，默认yes slave-read-only yes #当从失去与主的连接或者复制正在进行时，从是响应客户端（可能返回过期的数据）还是返回“SYNC with master in progress”错误，默认yes响应客户端 slave-serve-stale-data yes #从库按照默认10s的周期向主库发送PING测试连通性 repl-ping-slave-period 10 #设置复制超时时间（SYNC期间批量I/O传输、PING的超时时间），确保此值大于repl-ping-slave-period #repl-timeout 60 #当从断开与主的连接时的复制缓存区，仅当第一个从断开时创建一个，缓存区越大从断开的时间可以持续越长 # repl-backlog-size 1mb #当从与主断开持续多久时清空复制缓存区，此时从就需要全量复制了，如果设置为0将永不清空 # repl-backlog-ttl 3600 #slave客户端缓存区，如果缓存区超过256mb将直接断开与从的连接，如果持续60秒超过64mb也会断开与从的连接 client-output-buffer-limit slave 256mb 64mb 60 设置主从 123456789101112131415161718192021cd /usr/servers/redis-2.8.19 cp redis.conf redis_6660.conf cp redis.conf redis_6661.conf # 将端口分别改为port 6660和port 6661vim redis_6660.conf vim redis_6661.conf # 启动nohup /usr/servers/redis-2.8.19/src/redis-server /usr/servers/redis-2.8.19/redis_6660.conf &amp; nohup /usr/servers/redis-2.8.19/src/redis-server /usr/servers/redis-2.8.19/redis_6661.conf &amp; # 查看是否启动成功ps -aux | grep redis # 进入从客户端，挂主（不在配置文件设置 slaveof masterIP masterPort ）/usr/servers/redis-2.8.19/src/redis-cli -p 6661 127.0.0.1:6661&gt; slaveof 127.0.0.1 6660 OK 127.0.0.1:6661&gt; info replication # Replication role:slave ... Redis持久化 为了防止数据丢失，可以挂载一个从（叶子节点）只进行持久化存储工作。 Redis持久化有RDB快照模式和AOF追加模式。 Redis动态调整配置 123456789127.0.0.1:6660&gt; config get maxmemory 1) "maxmemory" 2) "10485760"# 调整配置值127.0.0.1:6660&gt; config set maxmemory 20971520 # 上述命令重启redis后该配置会丢失，可以执行如下命令重写配置文件127.0.0.1:6660&gt; config rewrite Redis集群一旦涉及到一台物理机无法存储的情况就需要考虑使用分片机制将数据存储到多台服务器，可以说是Redis集群。 利用 Twemproxy 实现分片、减少连接数、Hash Tag 分片逻辑。 Twemproxy 代理 Twemproxy 配置 12# 配置文件vim /usr/servers/twemproxy-0.4.0/conf/nutcracker.yml 1234567891011server1: listen: 127.0.0.1:1111 ## 监听地址和端口 hash: fnv1a_64 ## 散列算法 distribution: ketama ## 分片的算法，有ketama（一致性hash）、module（取模）、random（随机）三种算法# auto_eject_hosts: true ## 是否在节点无法响应时自动从服务器列表中剔除，重新响应时自动加入服务器列表中# timeout: 1000 hash_tag: "::" redis: true ## 后端代理的是否为redis servers: - 127.0.0.1:6660:1 server1 - 127.0.0.1:6661:1 server2 Twemproxy 启动 1234/usr/servers/twemproxy-0.4.0/src/nutcracker -d -c /usr/servers/twemproxy-0.4.0/conf/nutcracker.ymlps -aux | grep nutcracker# 启动 Redis 客户端对应端口，查看是否代理成功/usr/servers/redis-2.8.19/src/redis-cli -p 1111 或者配置启动/重启/停止脚本方便操作 12chmod +x /usr/servers/twemproxy-0.4.0/scripts/nutcracker.init vim /usr/servers/twemproxy-0.4.0/scripts/nutcracker.init 将OPTIONS改为 OPTIONS=”-d -c /usr/local/twemproxy/conf/nutcracker.yml” 注释掉. /etc/rc.d/init.d/functions； 将daemon –user ${USER} ${prog} $OPTIONS改为${prog} $OPTIONS； [报错]：若nutcracker没设置为全局变量，则会报此错 nutcracker: command not found 写了全路径：/usr/servers/twemproxy-0.4.0/src/${prog} $OPTIONS 将killproc改为killall。 这样就可以使用如下脚本进行启动、重启、停止了。 1nutcracker.init &#123;start|stop|status|restart|reload|condrestart&#125;]]></content>
      <categories>
        <category>数据库</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ForkJoin框架]]></title>
    <url>%2F2019%2F09%2F17%2FForkJoin%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[ForkJoin框架概要！ 参考文献： Java–8–新特性–串并行流与ForkJoin框架 ForkJoin框架概念Fork/Join框架：在必要的情况下，将一个大任务，进行拆分（fork） 成若干个子任务（拆到不能再拆，这里就是指我们制定的拆分的临界值），再将一个个小任务的结果进行join汇总。 Fork/Join与传统线程池的区别Fork/Join采用“工作窃取模式”，当执行新的任务时他可以将其拆分成更小的任务执行，并将小任务加到线程队列中，然后再从一个随即线程中偷一个并把它加入自己的队列中。 Java8 Stream APIStream并行流底层Fork/Join实现，使用Stream并行流更简洁。 1long count = Arrays.asList(bag).parallelStream().filter(balance::weight).count(); 参考： 请移步 java8新特性 Fork/Join框架与Java8 Stream API 之并行流的速度比较 Java8之Stream流（四）并行流]]></content>
      <categories>
        <category>java</category>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>ForkJoin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[template]]></title>
    <url>%2F2019%2F09%2F17%2Ftemplate%2F</url>
    <content type="text"><![CDATA[这是文章模板！ 参考文献： ## ##]]></content>
      <categories>
        <category>template</category>
        <category>template</category>
      </categories>
      <tags>
        <tag>template</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring笔记]]></title>
    <url>%2F2019%2F09%2F17%2Fspring%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[spring的一些坑！ 参考文献： spring容器 Spring中自己new出来的对象不能自动注入对象和属性 原因 @Autowired注入时是将类交给Springboot管理，而new出来的实例脱离了Springboot的管理，两个东西不在一个管理者管理下，所以没法联系在一起，@Autowired注入就会为null。 解决方法 不要用new的方式实例化，也采用注解的方式，在需要new的实例类上加@Component注解，通过注入的方式使用实例化类。 使用ApplicationContextAware和反射方式获取容器的bean重新set进去 参考：自己new的对象怎么注入spring管理的对象 ##]]></content>
      <categories>
        <category>java</category>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[wsl笔记]]></title>
    <url>%2F2019%2F09%2F17%2Fwsl%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[wsl 下的 ubuntu 系统一些问题总结！ 参考文献： Windows 10生产力提升之WSL实践 在wsl下安装使用sshd全攻略.md 环境win10 下 wsl 环境安装 ubuntu 修改更新源 备份文件 1sudo cp /etc/apt/sources.list /etc/apt/sources.list.old 使用阿里源 打开文件： 12 sudo vi /etc/apt/sources.list` 整个文件替换成阿里源： 12345678910deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse 更新 12sudo apt-get updatesudo apt-get upgrade 新建用户Linux 创建、删除和改变用户信息 —— adduser useradd usermod deluser linux用户管理（1）—-创建用户（adduser和useradd）和删除用户（userdel） adduser user1 ubuntu建用户最好用adduser，虽然adduser和useradd是一样的在别的linux糸统下，但是我在ubuntu下用useradd时，并没有创建同名的用户主目录。 12345678# 新建用户，会创建同名的用户主目录adduser user1# ubuntu查看用户列表cat /etc/passwd# 用linux代替想要删除的用户账户， -r 表示连同用户主目录一块删除userdel -r user1# 查看是否正确删除用户：id user1 设置超级用户ubuntu的su初始密码设置 1sudo passwd 环境变量 不同用户不共享环境变量 123# 所有用户都生效sudo vim /etc/profile source /etc/profile 存在退出终端后不生效问题！ 退出终端后不生效问题 123# 当前用户生效sudo vim ~/.bashrc ## 在每个用户的 ~/.bashrc 添加 source /etc/profile 共享全局的path zsh美化终端安装使用oh-my-zsh（Win10+WSL或Ubuntu） 设zsh为默认shell1chsh -s /bin/zsh # 设置 bash 同理 环境变量PATH使用zsh后，环境变量需要在 ~/.zshrc 配置文件中定义，/etc/profile 是不会生效的 开启 ssh 远程连接wsl下的ubuntu自带ssh服务有问题需要卸载重装一遍ssh服务 123456789101112# 重装 openssh-serversudo apt-get remove openssh-serversudo apt-get install openssh-server# 修改 shd_config文件sudo vi /etc/ssh/sshd_config# Port 22 #默认即可，如果有端口占用可以自己修改# PasswordAuthentication yes # 允许用户名密码方式登录# PermitRootLogin yes # 允许管理员ssh登录# 重启ssh服务sudo service ssh restart apt命令与问题[Ubuntu的apt命令详解] 搜索软件 1sudo apt-cache search package_name WSL Ubuntu 解决出现 E: Could not read response to hello message from hook …问题 执行以下命令 1sudo rm -rf /etc/apt/apt.conf.d/20snapd.conf windows 和 wsl 互相访问文件 打开wsl文件 使用explorer.exe，wsl下切换用户就不能使用这个命令。。。 1explorer.exe . 访问windows文件，使用挂载方式/mnt/ 1cd /mnt/c/Users/Ben/Documents/ wsl开机没有自启动ssh需要在wsl中手动运行一下： 1sudo service ssh start 由于是wsl内部是类似docker运行的，没有 systemd 服务 重装python 检查python路径： 123456789# 方式一：type -a python# 方式二：ls -l /usr/bin/pythonls -l /usr/bin/python*# 方式三：which python 安装python2、python3 1234# 安装python2$ sudo apt-get install python# 安装python3$ sudo apt-get install python3]]></content>
      <categories>
        <category>linux</category>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lombok插件]]></title>
    <url>%2F2019%2F09%2F17%2FLombok%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Lombok插件！ 参考文献： Lombok使用示例详情 idea 使用 Lombok plugin 插件ntellij idea 使用Lombok需要安装插件：Lombok plugin: Preferences —&gt; Plugins —&gt; 搜索 Lombok plugin — &gt; Install同时设置 Preferences -&gt; Compiler -&gt; Annotation Processors -&gt; Enable annotation processing勾选。 常见问题 Gradle使用Lombok的正确方式 gradle lombok 插件官方地址 需要改成大于5.4版本的gradle 指定版本lombok版本，避免升级的影响 build.gradle， 123456dependencies &#123; annotationProcessor 'org.projectlombok:lombok:1.18.2' compileOnly 'org.projectlombok:lombok:1.18.2' testAnnotationProcessor 'org.projectlombok:lombok:1.18.2' testCompileOnly 'org.projectlombok:lombok:1.18.2'&#125; “找不到符号” idea安装lombok插件,设置Enable Annotation Processing后 依然报错解决，更新idea 的 lombok插件 maven 工程引入lombok依赖1234567&lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.20&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 常用注解 @Getter/@Setter 为字段生成Getter和Setter方法，可以注解到字段或者类上(注解在类上会为类中的所有字段生成Getter和Setter方法)，默认是public类型的， 如果需要的话可以修改方法的访问级别，@Getter(AccessLevel.PROTECTED) @AllArgsConstructor生成一个全参数的构造方法 @Data@Data 包含了 @ToString、@EqualsAndHashCode、@Getter / @Setter的功能]]></content>
      <categories>
        <category>java</category>
        <category>代码生成</category>
      </categories>
      <tags>
        <tag>Lombok</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea使用技巧]]></title>
    <url>%2F2019%2F09%2F17%2Fidea%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[idea使用技巧！ 参考文献： 技巧 快捷键生成serialVersionUID IDEA快捷键生成serialVersionUID idea配置serializable class without ‘serialVersionUID’ 在对应类名上 alt+enter 即弹出对应选项 IDEA取消参数名称（形参名）提示 “File” -&gt; “Settings”-&gt;“Editor” -&gt; “General” -&gt; “Appearance”-&gt;“Show parameter name hints” 取消 踩坑 console中文乱码 settings设置UTF-8 tomcat 设置 -Dfile.encoding=utf-8 注意：IntelliJIDEA15.0.6\bin找到idea.exe.vmoption文件，这文件修改已经失效 替代方法：HELP-&gt;Edit Custom VM OPtions中加 -Dfile.encoding=utf-8 ​ 升级后覆盖vmoption文件后会都需要手动设置一下，并重启idea ​ 这个文件是在用户目录下的，而且命名不一定一致，所以直接在软件上操作]]></content>
      <categories>
        <category>编辑器</category>
        <category>idea</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[enum]]></title>
    <url>%2F2019%2F09%2F17%2Fenum%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[enum语法！ 参考文献： java enum的用法详解 枚举ENUM的tostring() valueof()name()和values()用法 Enum原理1public enum Size&#123; SMALL, MEDIUM, LARGE, EXTRA_LARGE &#125;; 实际上，这个声明定义的类型是一个类，它刚好有四个实例。 方法 枚举常用的方法是values():对枚举中的常量值进行遍历; valueof(String name) :根据名称获取枚举类中定义的常量值;要求字符串跟枚举的常量名必须一致; 获取枚举类中的常量的名称使用枚举对象.name() 枚举类中重写了toString()方法,返回的是枚举常量的名称;]]></content>
      <categories>
        <category>java</category>
        <category>语法</category>
      </categories>
      <tags>
        <tag>enum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java8新特性]]></title>
    <url>%2F2019%2F09%2F17%2Fjava8%E6%96%B0%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[java8新特性：函数式编程，stream流，Optional 类！ 参考文献： 理解、学习与使用 Java 中的 Optional Java8之Stream流（一）基础体验 java8 stream流操作的flatMap（流的扁平化） java中使用Lambda表达式的5种语法 Lambda语法 标准写法 1Arrays.sort(arr, (String m, String n) -&gt; Integer.compare(m.length(), n.length())); lambda表达式的标准写法由下面几点构成： 以逗号分隔，以（）关闭的形参：(Dog m, Dog n) 箭头标记：-&gt; 主体部分则是一个单表达式或者声明代码块。如下是单表达式形式：Integer.compare(m.getWeight(), n.getWeight()) 参数类型可以推断 如果参数的类型可以根据上下文推断出来，则可以省略掉类型 存在多行代码 需要{} 括起来，且代码应该有明确的返回语句 123456Arrays.sort(arr, (String m, String n) -&gt; &#123; if (m.length() &gt; n.length()) return -1; else return 0;&#125;); 单个参数并可推断类型 可以省略参数 “x” 的括号 方法引用 写成::形式，并省略参数。 1stream.forEach(System.out::println); 没有参数 () -&gt; {for(int i=0; i&lt;10; i++) doSomthing();} Optional 类包含有可选值的包装类，既可以含有对象也可以为空。 常用方法 ofNullable() 创建Optional对象：传入的对象即可能是 null 也可能是非 null，不会抛出异常NullPointerException ifPresent() 选择性执行语句：该方法除了执行检查，还接受一个Consumer(消费者) 参数，如果对象不是空的，就对执行传入的 Lambda 表达式： 1opt.ifPresent( u -&gt; assertEquals(user.getEmail(), u.getEmail())); 这个例子中，只有 user 用户不为 null 的时候才会执行断言。 orElseGet() 返回默认值：这个方法会在有值的时候返回值，如果没有值，它会执行作为参数传入的 Supplier(供应者) 函数式接口，并将返回其执行结果： 1User result = Optional.ofNullable(user).orElseGet( () -&gt; user2); orElse() 和 orElseGet() 的不同之处： Optional 对象返回非空值后，orElse() 方法仍然创建了 默认值 对象，而orElseGet() 方法不创建 默认值 对象。 orElseThrow() 在对象为空的时候抛出异常，而不是返回备选的值： 12345@Test(expected = IllegalArgumentException.class)public void whenThrowException_thenOk() &#123; User result = Optional.ofNullable(user) .orElseThrow( () -&gt; new IllegalArgumentException());&#125; 这个方法让我们有更丰富的语义，可以决定抛出什么样的异常，而不总是抛出 NullPointerException。 map() filter() Optional 类的链式方法 12345String result = Optional.ofNullable(user) .flatMap(User::getAddress) .flatMap(Address::getCountry) .map(Country::getIsocode) .orElse("default"); Stream流 概念 Java 8 中的 Stream 是对集合（Collection）对象功能的增强 专注于对集合对象进行各种非常便利、高效的聚合操作（aggregate operation） 大批量数据操作 (bulk data operation) 支持 Lambda 表达式 不是集合元素，它不是数据结构并不保存数据，它是有关算法和计算的 作用更像一个高级版本的 Iterator，与迭代器不同点，Stream 可以并行化操作，迭代器只能命令式地、串行化操作 Stream 的并行操作依赖于 Java7 中引入的 Fork/Join 框架（JSR166y）来拆分任务和加速处理过程 “终端操作”&amp;”中间操作” 终端操作： 会消费流，这种操作会产生一个结果的 iterator()、 spliterator()、min()、max()、forEach() 中间操作：会产生另一个流，类似管道 缩减操作 缩减操作的三个约束条件 无状态 不干预 关联性 reduce()-通用的方法，而min()和max()，count()这些操作称为特例缩减。 12T reduce(T identity, BinaryOperator&lt;T&gt; accumulator);//1Optional&lt;T&gt; reduce(BinaryOperator&lt;T&gt; accumulator);//2 第一个版本的identity为初始化值（兼容单个值的情况），求和的时候为0，求积的时候它的值为1。 其中的accumulator是一个BinaryOperator的类型，他是java.util.function包中声明的函数式接口，它扩展了BiFunction函数式接口. 12345678@FunctionalInterfacepublic interface BinaryOperator&lt;T&gt; extends BiFunction&lt;T,T,T&gt; &#123;&#125;@FunctionalInterfacepublic interface BiFunction&lt;T, U, R&gt; &#123; R apply(T t, U u);//notice&#125; apply()对他的两个操作数(t,u)应用到同一个函数上，并返回结果 12# 直接函数式编程reduce((a, b) -&gt; a + b) 并行流 对流调用一下parallel()，或者Collection.parallelStream() 在reduce()的第三版本比较适合并行流，accumulator被称为累加器， combiner被称为合成器， combiner定义的函数将accumulator提到的两个值合并起来 123456public interface Stream&lt;T&gt; extends BaseStream&lt;T, Stream&lt;T&gt;&gt; &#123;//、、、忽略其他无关紧要的元素&lt;U&gt; U reduce(U identity, BiFunction&lt;U, ? super T, U&gt; accumulator, BinaryOperator&lt;U&gt; combiner);｝ 顺序流&amp;并行流&amp;无序流之间的切换操作 在使用并行流时，有时候流是无序的就能获得性能上的提升，可以通过BaseStream接口提供的unordered()方法把流转换成一个无序流之后，再进行各种操作 forEach()方法不一定会保留并行流的顺序，如果在对并行流的每个元素执行操作时，也希望保留顺序，那么可以使用forEachOrdered()方法，它的用法和forEach()是一样的。 forEach底层采用的是迭代器的方式。如果数据结构是ArrayList这种数据结构，那你可以采用for,但是你的数据结构如果是LinkList那你千万别再用for,应该果断采用forEach,因为数据一多起来的，for此时的效率低得可怜 映射 filter方法 filter方法的参数是一个Predicate对象，即一个从T到boolean的函数，返回为true的 map方法 对一个流中的值进行某种形式的转换，返回的是对应类型的Stream对象。 flatMap方法 flat – 摊平，流的扁平化 flatMap()操作能把原始流中的元素进行一对多的转换，并且将新生成的元素全都合并到它返回的流里面，即重新整合为一个流。 将多个Stream连接成一个Stream，这时候不是用新值取代Stream的值，与map有所区别，这是重新生成一个Stream对象取而代之。 12345678String[] words = new String[]&#123;"Hello","World"&#125;;List&lt;String&gt; a = Arrays.stream(words) .map(word -&gt; word.split("")) .flatMap(Arrays::stream) .distinct() .collect(toList());a.forEach(System.out::print);// 输出 ["H","e","l","o","W","r","d"] 收集功能 Collectors类 12public static &lt;T&gt; Collector&lt;T, ?, List&lt;T&gt;&gt; toList()public static &lt;T&gt; Collector&lt;T, ?, Set&lt;T&gt;&gt; toSet() 用法：steam.collect(Collectors.toList) collect方法 123&lt;R&gt; R collect(Supplier&lt;R&gt; supplier, BiConsumer&lt;R, ? super T&gt; accumulator, BiConsumer&lt;R, R&gt; combiner); 类似上面的缩减操作。其中supplier指定如何创建用于保存结果的对象，比如，要使用ArrayList作为结果的集合，需要指定它的构造函数，accumulator函数是将一个元素添加到结果中，而combiner函数合并两个部分的结果 1234567891011121314private static void learnCollect() &#123; List&lt;HeroPlayerGold&gt; lists = new ArrayList&lt;&gt;(); lists.add(new HeroPlayerGold("盖伦", "RNG-Letme", 100)); lists.add(new HeroPlayerGold("诸葛亮", "RNG-Xiaohu", 300)); lists.add(new HeroPlayerGold("露娜", "RNG-MLXG", 300)); lists.add(new HeroPlayerGold("狄仁杰", "RNG-UZI", 500)); lists.add(new HeroPlayerGold("牛头", "RNG-Ming", 500)); lists.stream().collect(HashSet::new, HashSet::add, HashSet::addAll ).forEach(System.out::println);&#125; SpliteratorSpliterator是Java8新增的一种迭代器，Spliterator支持并行迭代。]]></content>
      <categories>
        <category>java</category>
        <category>java8</category>
      </categories>
      <tags>
        <tag>java8</tag>
        <tag>函数式编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven笔记]]></title>
    <url>%2F2019%2F09%2F17%2Fmaven%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[maven笔记！ 参考文献： 指定编码和编译版本pom.xml会覆盖idea的Project Structure设置的编译版本，需要在在pom.xml中指定 1234567891011121314151617181920&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;utf-8&lt;/project.reporting.outputEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;&lt;/properties&gt;# 或者&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;8&lt;/source&gt; &lt;target&gt;8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; ##]]></content>
      <categories>
        <category>java</category>
        <category>构建工具</category>
      </categories>
      <tags>
        <tag>maven笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发调试]]></title>
    <url>%2F2019%2F09%2F17%2F%E5%B9%B6%E5%8F%91%E8%B0%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[并发调试、工具、容器！ 参考文献： Tomcat7 性能优化，提高并发-NIO模式 彻底搞懂面试中被问到的spring的单例多线程问题 详细理解单例模式与多线程+阿里面试题+面试心得 volatile 关键字 volatile 关键字的作用（变量可见性、禁止重排序），不能保证原子性 使用场景 通常修饰状态（boolean和int） 单纯的赋值 同步机制 监视器锁（synchronized） 悲观锁 显示锁（ReentrantLock、ReadWriteLock） 还提供了诸如可响应中断锁、可轮询锁请求、定时锁等避免多线程死锁的方法 原子变量（AtomicInteger、AtomicLong、AtomicBoolean） 乐观锁、CAS（比较提换） volatile 线程封闭（模拟单线程，规避多线程环境） 不共享数据 栈封闭 ThreadLocal 发令枪CountDownLatch（线程计数器 ） 123456static CountDownLatch cdl = new CountDownLatch(20);... cdl.countDown(); // 此处要调用20次...cdl.await(); // 阻塞，countDown计数20次后才统一走下一步程序// 类似发令枪，统一起跑 Tomcat7 和 Tomcat8 的默认IO模型区别tomcat7默认使用BIO，一个请求对应一个线程，阻塞 tomcat8默认使用NIO，一个线程可处理多个请求，非阻塞 启动NIO模式 修改tomcat7为NIO 123&lt;Connector port="8080"protocol="org.apache.coyote.http11.Http11NioProtocol" connectionTimeout="20000" redirectPort="8443"/&gt; 线程池 默认的tomcat没有启用线程池，在tomcat中每一个用户请求都是一个线程，所以可以使用线程池提高性能。这里前台其实有一个调度线程，然后调度线程会放入线程池内，然后到到一定的时候线程池的任务变成工作线程 放开配置文件的下面注释，并在Connector中指定执行器 1234567&lt;Executor name="tomcatThreadPool" namePrefix="catalina-exec-" maxThreads="150" minSpareThreads="4"/&gt;&lt;!-- executor="tomcatThreadPool"为上面的执行器 --&gt;&lt;Connector executor="tomcatThreadPool" port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; spring 单例支持多线程并发为什么局部变量不会受多线程影响？ 对于那些会以多线程运行的单例类，例如Web应用中的Servlet，每个方法中对局部变量的操作都是在线程自己独立的内存区域内完成的，所以是线程安全的 局部变量不会受多线程影响 成员变量会受到多线程影响 对于成员变量的操作，可以使用ThreadLocal来保证线程安全 在bean对象中定义一个ThreadLocal成员变量，将需要的可变成员变量保存在ThreadLocal中]]></content>
      <categories>
        <category>java</category>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ant笔记]]></title>
    <url>%2F2018%2F09%2F17%2Fant%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[ant的使用，命令！ 参考文献： ant+maven一键打包springboot上传服务器发布 判断linux文件、文件夹是否存在 shell中脚本参数传递的两种方式 shell脚本“syntax error:unexpected end of file”解决方案 ant远程部署 Ant 引用配置文件 123456789&lt;!-- set global properties for this build --&gt; &lt;property file="build.properties"/&gt; &lt;!--输出配置信息--&gt; &lt;target name="show_property" description="show build.properties conf"&gt; &lt;echo&gt; ================== build.properties ================ &lt;/echo&gt; &lt;echo&gt;PROJECT_NAME=$&#123;ant.project.name&#125;&lt;/echo&gt; &lt;echo&gt;DEST_DIR=$&#123;DEST_DIR&#125;&lt;/echo&gt;&lt;/target&gt; target条件控制 12345678910&lt;target name="detect.file" &gt; &lt;condition property="fileIsExists" &gt; &lt;and&gt; &lt;available file="c:/123.txt"/&gt; &lt;/and&gt; &lt;/condition&gt;&lt;/target&gt;&lt;target name="echoDemo" if="fileIsExists" depends="detect.file"&gt; &lt;echo message="hello ant"/&gt;&lt;/target&gt; Ant-sshexec-执行远程服务器或本地脚本 需要先下载第三方依赖包jsch-0.1.46.jar到ant/lib目录 12345678&lt;sshexec host="$&#123;host&#125;"username="$&#123;usr&#125;" password="$&#123;pwd&#125;"trust="true" command="pwd;./test.sh" outputproperty="output" # sh 的输出，可用 $&#123;output&#125; 获取/&gt; scp命令上传文件 1234567&lt;scp todir="$&#123;USERNAME&#125;:$&#123;PASSWORD&#125;@$&#123;SERVER&#125;:$&#123;DEST_DIR&#125;" trust="true"&gt; &lt;fileset dir="$&#123;LOCAL_PATH&#125;"&gt; &lt;exclude name="build.properties"/&gt; &lt;exclude name="build.xml"/&gt; &lt;exclude name=".idea/"/&gt; &lt;/fileset&gt;&lt;/scp&gt; 判断远程文件是否存在 123456#判断文件是否存在if [ -f "/data/filename" ];then echo "文件存在" else echo "文件不存在"fi shell脚本传参 123456789101112#!/bin/bashecho "脚本$0"echo "第一个参数$1"echo "第二个参数$2"# 命令行输入$ ./test.sh 1 2#shell中将会输出：脚本./test.sh # $0获取到的是脚本路径以及脚本名# 后面按顺序获取参数，当参数超过10个时(包括10个)，需要使用$&#123;10&#125;,$&#123;11&#125;....才能获取到参数第一个参数1第二个参数2 shell脚本添加执行权限 chmod是权限管理命令change the permissions mode of a file的缩写。。 u代表所有者，x代表执行权限。 + 表示增加权限。 12chmod u+x file.sh # 就表示对当前目录下的file.sh文件的所有者增加可执行权限。 shell脚本“syntax error:unexpected end of file”解决方案 原因：该脚本在windows下编辑或者在windows打开保存过。 DOS下文件和Linux下文件格式差异问题导致的。 在 idea 中右下角可以选择 LF 为换行标识。 在 服务器可以使用vi修改文件格式，如下： 123vi dos.txt:set fileformat=unix:wq]]></content>
      <categories>
        <category>java</category>
        <category>构建工具</category>
      </categories>
      <tags>
        <tag>ant</tag>
      </tags>
  </entry>
</search>
